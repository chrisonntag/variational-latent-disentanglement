{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e727dd-2204-4997-a8c9-e89ebaf54922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers.merge import concatenate as concat\n",
    "import numpy as np\n",
    "from model.vae.vae_fashionmnist import VariationalAutoEncoderMNIST\n",
    "from util.experiment import Experiment, load_experiments\n",
    "from util.plotting import plot_label_clusters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "\n",
    "# Interactive tools\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d91c15-3ce9-4fa3-86cc-24c62adf3a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 15:55:09.467371: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(_, _), (valid_images, valid_labels) = fashion_mnist.load_data()\n",
    "valid_images = valid_images.astype(\"float32\") / 255.0\n",
    "valid_images = tf.expand_dims(valid_images, axis=-1)\n",
    "\n",
    "class_names = ['T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad196cb8-e79e-4fc5-8e1c-7b902d733bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = \"branchedClassifier\"\n",
    "MODEL_NAME = \"1416_speak-leave-easy-money\"\n",
    "#MODEL_NAME = \"1402_die-continue-entire-room\"\n",
    "EXAMPLE_IMAGE = tf.expand_dims(valid_images[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296336db-33c7-4d4c-9fd4-5ca95276512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "{'optimizer': 'Adam', 'learning_rate': 0.001, 'epochs': 30, 'batch_size': 32, 'latent_dim': 10, 'beta': 8}\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(name=MODEL_NAME, base_path=\"experiments/\"+RUN_NAME)\n",
    "base_model = experiment.load_model()\n",
    "params = {'input_dim': (28, 28, 1), 'z_dim': experiment.params['latent_dim'], 'beta': experiment.params['beta']}\n",
    "model = VariationalAutoEncoderMNIST.from_saved_model(base_model, params)\n",
    "model.compile()\n",
    "\n",
    "print(experiment.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3beb7382-e1fc-4ab5-99cf-c441ad3865c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(img):\n",
    "    z_mean, z_log_var, _ = model.encode(img)\n",
    "    z = model.reparameterize(z_mean, z_log_var)\n",
    "    \n",
    "    reco = model.decode(z)\n",
    "    reco = tf.sigmoid(reco)\n",
    "    \n",
    "    return z_mean, z_log_var, z, reco\n",
    "\n",
    "# Forward pass\n",
    "z_mean, z_log_var, z, reco = forward_pass(EXAMPLE_IMAGE)\n",
    "stddev = 2*tf.exp(z_log_var)\n",
    "reco_img = plt.cm.Greys(reco.numpy().squeeze(), bytes=True)\n",
    "z_tmp = copy.deepcopy(z.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e17e8-1fbd-41d5-8531-43700e9669c9",
   "metadata": {},
   "source": [
    "# Global Sensitivity Measure\n",
    "\n",
    "- Fix one dimension\n",
    "- Sample over the other dimensions\n",
    "\n",
    "You can learn what variables would need to be changed to drive the solution in a given direction or control the system. If your model is exact and the parameters are known, the \"standard\" methods apply, but if your model is only approximate, a global sensitivity metric may be a better prediction as to how variables cause changes.\n",
    "\n",
    "You can learn if there are any variables which do not have a true effect on the output. These variables would be practically unidentifiable from data and models can be reduced by removing the terms. It also is predictive as to robustness properties.\n",
    "\n",
    "You can find ways to automatically sparsify a model by dropping off the components which contribute the least. This matters in automatically generated or automatically detected models, where many pieces may be spurious and global sensitivities would be a method to detect that in a manner that is not sensitive to the chosen parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7858bc74-e1d4-44ae-955e-4f8b9ad5c060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
