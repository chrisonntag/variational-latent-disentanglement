{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e727dd-2204-4997-a8c9-e89ebaf54922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers.merge import concatenate as concat\n",
    "import numpy as np\n",
    "from model.vae.branched_classifier_vae import BranchedClassifierVAE\n",
    "from model.vae.conditional_vae import ConditionalVAE\n",
    "from util.experiment import Experiment, load_experiments\n",
    "from util.plotting import plot_label_clusters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "\n",
    "# Interactive tools\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7eff740-276b-4467-a551-ab91f8452e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_categorical(y):\n",
    "    y = np.array(y, dtype='int')\n",
    "    return np.argmax(y, axis=len(y.shape)-1)\n",
    "\n",
    "def dict_pretty_print(dictionary):\n",
    "    res = \"\"\n",
    "    for key, value in dictionary.items():\n",
    "        res += f\"{key}: {value}\\n\"\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a21c74-f123-479a-ad45-811d0c9b5b07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad196cb8-e79e-4fc5-8e1c-7b902d733bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DIMS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec46577-9ca6-48d8-b814-8e7681212492",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"fashion_mnist\": {\n",
    "        \"loader\": keras.datasets.fashion_mnist,\n",
    "        \"class_names\": ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    },\n",
    "    \"mnist\": {\n",
    "        \"loader\": keras.datasets.mnist,\n",
    "        \"class_names\": ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "selectors = {\n",
    "    'fashion_mnist': {\n",
    "        'conditionalVAE': {\n",
    "            '1630_help-mean-hard-world': {},\n",
    "            '1632_speak-cultural-young-girl': {},\n",
    "            '1635_remain-nice-head-area': {},\n",
    "            '1638_add-love-dead-business': {},\n",
    "        },\n",
    "        'branchedClassifier': {\n",
    "            '1333_live-similar-big-child': {},\n",
    "            '1347_will-late-year-business': {},\n",
    "            '1416_speak-leave-easy-money': {},\n",
    "            '1402_die-continue-entire-room': {}\n",
    "        }\n",
    "    }, \n",
    "    'mnist': {\n",
    "        'conditionalVAEMNIST': {\n",
    "            '1137_meet-large-line-back': {},\n",
    "            '1141_would-green-medical-morning': {},\n",
    "            '1143_buy-left-place-head': {},\n",
    "            '1146_stand-open-cold-month': {},\n",
    "        },\n",
    "        'branchedVAEMNIST': {\n",
    "            '1219_love-early-better-service': {},\n",
    "            '1222_stop-available-office-education': {},\n",
    "            '1225_know-happy-minute-force': {},\n",
    "            '1227_grow-hot-book-water': {},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d91c15-3ce9-4fa3-86cc-24c62adf3a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 10:27:33.297408: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "fashion_mnist conditionalVAE 1630_help-mean-hard-world\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "fashion_mnist conditionalVAE 1632_speak-cultural-young-girl\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "fashion_mnist conditionalVAE 1635_remain-nice-head-area\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "fashion_mnist conditionalVAE 1638_add-love-dead-business\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "fashion_mnist branchedClassifier 1333_live-similar-big-child\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "fashion_mnist branchedClassifier 1347_will-late-year-business\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "fashion_mnist branchedClassifier 1416_speak-leave-easy-money\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "fashion_mnist branchedClassifier 1402_die-continue-entire-room\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "mnist conditionalVAEMNIST 1137_meet-large-line-back\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "mnist conditionalVAEMNIST 1141_would-green-medical-morning\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "mnist conditionalVAEMNIST 1143_buy-left-place-head\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "mnist conditionalVAEMNIST 1146_stand-open-cold-month\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "mnist branchedVAEMNIST 1219_love-early-better-service\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "mnist branchedVAEMNIST 1222_stop-available-office-education\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "mnist branchedVAEMNIST 1225_know-happy-minute-force\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "mnist branchedVAEMNIST 1227_grow-hot-book-water\n"
     ]
    }
   ],
   "source": [
    "for dataset in selectors.keys(): \n",
    "    for run in selectors[dataset].keys():\n",
    "        for model_name in selectors[dataset][run].keys():\n",
    "            # Load dataset\n",
    "            # Create dataset\n",
    "            (_, _), (valid_images, valid_labels) = datasets[dataset]['loader'].load_data()\n",
    "            valid_images = valid_images.astype(\"float32\") / 255.0\n",
    "            valid_images = tf.expand_dims(valid_images, axis=-1)\n",
    "\n",
    "            valid_images = valid_images[:3000]\n",
    "            valid_labels = valid_labels[:3000]\n",
    "            \n",
    "            # Load experiment and model\n",
    "            experiment = Experiment(name=model_name, base_path=\"experiments/\"+run)\n",
    "            base_model = experiment.load_model()\n",
    "            params = {'input_dim': (28, 28, 1), 'z_dim': experiment.params['latent_dim'], 'label_dim': 10, 'beta': experiment.params['beta']}\n",
    "            \n",
    "            # Create model and latent vector space from validation set\n",
    "            if 'conditional' in run:\n",
    "                model = ConditionalVAE.from_saved_model(base_model, params)\n",
    "                model.compile()\n",
    "                valid_labels = keras.utils.to_categorical(valid_labels)\n",
    "                class_names = datasets[dataset]['class_names']\n",
    "                \n",
    "                concat = model.concat_image_label([valid_images, valid_labels])\n",
    "                z_mean, z_log_var = model.encoder(concat)\n",
    "                train_labels_decoded = [class_names[i] for i in from_categorical(valid_labels)]\n",
    "            else:\n",
    "                model = BranchedClassifierVAE.from_saved_model(base_model, params)   \n",
    "                model.compile()\n",
    "                class_names = datasets[dataset]['class_names']\n",
    "                \n",
    "                z_mean, z_log_var, _ = model.encoder(valid_images)\n",
    "                train_labels_decoded = [class_names[i] for i in valid_labels]\n",
    "            \n",
    "            labels_df = pd.DataFrame(train_labels_decoded, columns = ['classname'])\n",
    "            cols = ['z'+str(i) for i in range(0, z_mean.shape[1])]\n",
    "            z_df = pd.DataFrame(z_mean, columns=cols)\n",
    "            \n",
    "            print(dataset, run, model_name)\n",
    "            \n",
    "            selectors[dataset][run][model_name]['experiment'] = experiment\n",
    "            selectors[dataset][run][model_name]['model'] = model\n",
    "            selectors[dataset][run][model_name]['z'] = z_df\n",
    "            selectors[dataset][run][model_name]['labels'] = labels_df\n",
    "            selectors[dataset][run][model_name]['class_names'] = class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e3e43-a836-4660-9bad-da3752697706",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa69a5-6d38-4c7d-8f93-711be06d87a2",
   "metadata": {},
   "source": [
    "## Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86c65e1-6c77-4612-85e1-dcd7f21940ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bz/z6j3rgzx6kjcvd1jjr276s9c0000gn/T/ipykernel_1207/2938860490.py:5: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "/var/folders/bz/z6j3rgzx6kjcvd1jjr276s9c0000gn/T/ipykernel_1207/2938860490.py:6: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import base64\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "\n",
    "def NamedSlider(name, short, style, min, max, step, val):\n",
    "    #marks = {i: np.round(val, 2) for i, val in enumerate(steps)}\n",
    "\n",
    "    return html.Div(\n",
    "        style=style,\n",
    "        children=[\n",
    "            f\"{name}:\",\n",
    "            html.Div(\n",
    "                style={\"margin-left\": \"5px\"},\n",
    "                children=[\n",
    "                    dcc.Slider(\n",
    "                        id=f\"slider-{short}\",\n",
    "                        min=min,\n",
    "                        max=max,\n",
    "                        step=step,\n",
    "                        value=val,\n",
    "                        marks=None,\n",
    "                        tooltip={\"placement\": \"bottom\", \"always_visible\": True}\n",
    "                    )\n",
    "                ],\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_dim_sliders(visible, values=None, classname=None, dist=None, latent_dims=MAX_DIMS):\n",
    "    sliders = []\n",
    "        \n",
    "    for dim in range(0, latent_dims):\n",
    "        slider_min = -3\n",
    "        slider_max = 3\n",
    "            \n",
    "        if dim <= visible-1:\n",
    "            hide = False\n",
    "            \n",
    "            if dist is not None and classname is not None:\n",
    "                slider_min = dist[f'pc{dim+1}']['mean'][classname]-dist[f'pc{dim+1}']['std'][classname]\n",
    "                slider_max = dist[f'pc{dim+1}']['mean'][classname]+dist[f'pc{dim+1}']['std'][classname]\n",
    "        else:\n",
    "            hide = True\n",
    "            \n",
    "            \n",
    "        sliders.append(\n",
    "            NamedSlider(\n",
    "                name=f\"pc{dim+1}\",\n",
    "                short=f\"pc{dim+1}\",\n",
    "                style={\"display\": \"none\"} if hide else {\"margin\": \"25px 5px 30px 0px\"},\n",
    "                min=slider_min,\n",
    "                max=slider_max,\n",
    "                step=0.01,\n",
    "                val=values[dim] if values is not None and not hide else 0\n",
    "            )\n",
    "        )\n",
    "    return sliders\n",
    "\n",
    "\n",
    "def numpy_to_b64(array, upscale=True, scalar=True):\n",
    "    # Convert from 0-1 to 0-255\n",
    "    if scalar:\n",
    "        array = np.uint8(255 * array)\n",
    "\n",
    "    im_pil = Image.fromarray(array)\n",
    "    if upscale:\n",
    "        im_pil = im_pil.resize((250, 250), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    buff = BytesIO()\n",
    "    im_pil.save(buff, format=\"png\")\n",
    "    im_b64 = base64.b64encode(buff.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    return im_b64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289cce76-aa1e-4c6f-b026-5357152bf065",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Latent Space Visualization\"\n",
    "\n",
    "init_dataset_option = list(selectors.keys())[0]\n",
    "init_run_option = list(selectors[init_dataset_option].keys())[0]\n",
    "init_model_option = list(selectors[init_dataset_option][init_run_option].keys())[0]\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "app.title = title\n",
    "app.layout = html.Div(children=[\n",
    "    html.H2(title),\n",
    "    html.Div(children=[\n",
    "        # Scatter Plot Matrix, left column\n",
    "        html.Div(children=[\n",
    "            html.P(\"Select dataset, experiment and model:\"),\n",
    "            html.Div(children=[\n",
    "                html.Div(children=[\n",
    "                    dcc.Dropdown(list(selectors.keys()), init_dataset_option, id='dataset-dropdown'),\n",
    "                    dcc.Dropdown(list(selectors[init_dataset_option].keys()), init_run_option, id='run-dropdown'),\n",
    "                    dcc.Dropdown(list(selectors[init_dataset_option][init_run_option].keys()), init_model_option, id='model-dropdown'),\n",
    "                ], style={'padding': 10, 'flex': 1}),\n",
    "                html.Div(children=[\n",
    "                    html.Pre(id=\"experiment-info\", children=\"No data\", className=\"dash-pre\")\n",
    "                ], style={'padding': 10, 'flex': 1}),\n",
    "            ], style={'display': 'flex', 'flex-direction': 'row'}),\n",
    "            dcc.Graph(id=\"spm-graph\"),\n",
    "            html.P(\"Number of components:\"),\n",
    "            dcc.Slider(id='pca-slider', min=2, max=2, value=2, step=1)\n",
    "        ], style={'padding': 10, 'flex': 1}),\n",
    "\n",
    "        # Reconstructed image, right column\n",
    "        html.Div(children=[\n",
    "            html.Div(children=[\n",
    "                html.Div(children=[\n",
    "                    html.Div(\n",
    "                        id=\"reconstruction-message-div\",\n",
    "                        style={\n",
    "                            \"text-align\": \"center\",\n",
    "                            \"margin-bottom\": \"7px\",\n",
    "                            \"font-weight\": \"bold\",\n",
    "                        },\n",
    "                        children=[html.H4(\"Select a sample in the SPM to modify latent components\")]\n",
    "                    ),\n",
    "                    html.Div(id=\"reconstruction-image-div\"),\n",
    "                    html.Div(id=\"z-slider-div\", children=generate_dim_sliders(0, latent_dims=MAX_DIMS)),\n",
    "                ], style={'padding': 10, 'flex': 1}),\n",
    "                html.Div(children=[\n",
    "                    html.Pre(id=\"raw-information-pre\", children=\"No data\", className=\"dash-pre\")\n",
    "                ], style={'padding': 10, 'flex': 1, 'width': '300px'}),\n",
    "            ], style={'display': 'flex', 'flex-direction': 'row'}),\n",
    "        ], style={'padding': 10, 'flex': 1}),\n",
    "    ], style={'display': 'flex', 'flex-direction': 'row'}),\n",
    "    \n",
    "    dcc.Store(id='sharedClickData')\n",
    "])\n",
    "\n",
    "\n",
    "def gen_figure_placeholder():\n",
    "    empty_fig = go.Figure()\n",
    "    empty_fig.update_layout({\n",
    "        \"xaxis\": {\n",
    "        \"visible\": False\n",
    "        },\n",
    "        \"yaxis\": {\n",
    "            \"visible\": False\n",
    "        },\n",
    "        \"annotations\": [\n",
    "            {\n",
    "                \"text\": \"Select dataset and model.\",\n",
    "                \"xref\": \"paper\",\n",
    "                \"yref\": \"paper\",\n",
    "                \"showarrow\": False,\n",
    "                \"font\": {\n",
    "                    \"size\": 28\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    "    return empty_fig\n",
    "\n",
    "\n",
    "def get_dim_reducer(n_components, z_df):\n",
    "    reducer = PCA(n_components=n_components)\n",
    "    projections = reducer.fit_transform(z_df)\n",
    "    #reducer = UMAP(n_components=n_components)\n",
    "    #projections = reducer.fit_transform(z_df)\n",
    "    \n",
    "    return reducer, projections\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('run-dropdown', 'options'),\n",
    "    Input('dataset-dropdown', 'value')\n",
    ")\n",
    "def init_run_dropdown(dataset):\n",
    "    if dataset is None:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        options = list(selectors[dataset].keys())\n",
    "    except KeyError as e:\n",
    "        return []\n",
    "    return options\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('model-dropdown', 'options'),\n",
    "    [\n",
    "        Input('dataset-dropdown', 'value'),\n",
    "        Input('run-dropdown', 'value')\n",
    "    ]\n",
    ")\n",
    "def init_model_dropdown(dataset, run):\n",
    "    if dataset is None or run is None:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        options = list(selectors[dataset][run].keys())\n",
    "    except KeyError as e:\n",
    "        return []\n",
    "    return options\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [\n",
    "        Output(\"pca-slider\", \"max\"),\n",
    "        Output(\"pca-slider\", \"value\"),\n",
    "        Output(\"experiment-info\", \"children\"),\n",
    "    ],\n",
    "    [\n",
    "        Input('dataset-dropdown', 'value'),\n",
    "        Input('run-dropdown', 'value'),\n",
    "        Input('model-dropdown', 'value')\n",
    "    ]\n",
    ")\n",
    "def init_pca_slider(dataset, run, model_name):\n",
    "    if dataset is None or run is None or model_name is None:\n",
    "        return MAX_DIMS, MAX_DIMS, \"No data\"\n",
    "    \n",
    "    try:\n",
    "        experiment = selectors[dataset][run][model_name]['experiment']\n",
    "        return experiment.params['latent_dim'], experiment.params['latent_dim'], dict_pretty_print(experiment.params)\n",
    "    except KeyError as e:\n",
    "        return MAX_DIMS, MAX_DIMS, \"No data\"\n",
    "\n",
    "\n",
    "# Dim Red Slider callback\n",
    "@app.callback(\n",
    "    [\n",
    "        Output(\"spm-graph\", \"figure\"),\n",
    "        Output(\"reconstruction-image-div\", \"children\"),\n",
    "        Output(\"z-slider-div\", \"children\"),\n",
    "        Output(\"reconstruction-message-div\", \"children\"),\n",
    "        Output(\"raw-information-pre\", \"children\"),\n",
    "        Output(\"sharedClickData\", \"data\"),\n",
    "    ],\n",
    "    [State(\"spm-graph\", \"figure\")],\n",
    "    [\n",
    "        Input(\"pca-slider\", \"value\"),\n",
    "        Input('dataset-dropdown', 'value'),\n",
    "        Input('run-dropdown', 'value'),\n",
    "        Input('model-dropdown', 'value'),\n",
    "        Input(\"spm-graph\", \"clickData\"), \n",
    "        Input(\"sharedClickData\", \"data\"),\n",
    "    ] + [Input(f\"slider-pc{dim+1}\", \"value\") for dim in range(0, MAX_DIMS)]\n",
    ")\n",
    "def run_and_plot(figureState, n_components, dataset, run, model_name, clickData, sharedClickData, *args):\n",
    "    if dataset is None or run is None or model_name is None:   \n",
    "        return gen_figure_placeholder(), None, generate_dim_sliders(0, latent_dims=MAX_DIMS), html.H4(\"\"), None, None\n",
    "    \n",
    "    experiment = selectors[dataset][run][model_name]['experiment']\n",
    "    \n",
    "    # Render SPLOM\n",
    "    pca, components = get_dim_reducer(n_components, selectors[dataset][run][model_name]['z'])\n",
    "    var = pca.explained_variance_ratio_.sum() * 100\n",
    "    title = f'SPLOM: Total Explained Variance: {var:.2f}%'\n",
    "    #title=\"SPLOM\"\n",
    "\n",
    "    labels = [f\"PC {i+1}\" for i in range(n_components)]\n",
    "\n",
    "    components_df = pd.DataFrame(components, columns=labels)\n",
    "    components_labeled_df = pd.concat([selectors[dataset][run][model_name]['labels'], components_df], axis=1)\n",
    "    \n",
    "    if clickData:\n",
    "        if clickData != sharedClickData:\n",
    "            print(\"# Fill Sliders and Decode image with a new clicked image\")\n",
    "            figure = figureState\n",
    "            point = np.array([clickData[\"points\"][0][f\"dimensions[{i}].values\"] for i in range(0, n_components)]).astype(np.float32)\n",
    "            \n",
    "            curve_number = clickData[\"points\"][0][\"curveNumber\"]\n",
    "            trace_name = figure[\"data\"][curve_number][\"name\"]\n",
    "\n",
    "            z = pca.inverse_transform(point)\n",
    "            z_transformed = tf.expand_dims(z, axis=0)\n",
    "            # Decode from latent space\n",
    "            model = selectors[dataset][run][model_name]['model']\n",
    "            reco_z = model.decode(z_transformed)\n",
    "            reco_z = plt.cm.Greys(reco_z.numpy().squeeze(), bytes=True)\n",
    "\n",
    "            image_b64 = numpy_to_b64(reco_z, upscale=True, scalar=False)\n",
    "            img_el = html.Img(\n",
    "                src=\"data:image/png;base64, \" + image_b64,\n",
    "                style={\"height\": \"25vh\", \"display\": \"block\", \"margin\": \"auto\"},\n",
    "            )\n",
    "\n",
    "            comp_df = pd.DataFrame(components, columns=[f\"pc{d+1}\" for d in range(0, n_components)])\n",
    "            comp_agg_df = pd.concat([selectors[dataset][run][model_name]['labels'], comp_df], axis=1).groupby(\"classname\").agg([\"mean\", \"std\"])\n",
    "\n",
    "            raw = \"Class: \" + trace_name + \"\\n\\n\"\n",
    "            raw += \"Original components: \\n\" + str(point) + \"\\n\\n\"\n",
    "            raw += \"Latent vector z: \\n\" + str(z) + \"\\n\\n\"\n",
    "            raw += \"Inner Class Distribution:\\n\" + str(comp_agg_df.loc[trace_name,:]) + \"\\n\\n\"\n",
    "\n",
    "            return figure, img_el, generate_dim_sliders(n_components, values=point, classname=trace_name, dist=comp_agg_df, latent_dims=MAX_DIMS), None, raw, clickData\n",
    "        else:\n",
    "            print(\"# Fill Sliders with updated values on already selected sample\")\n",
    "            # Transform component sliders to latent space\n",
    "            figure = figureState\n",
    "            slider_values = [val for val in args[:n_components]]\n",
    "            point = np.array(slider_values).astype(np.float32)\n",
    "            \n",
    "            curve_number = clickData[\"points\"][0][\"curveNumber\"]\n",
    "            trace_name = figure[\"data\"][curve_number][\"name\"]\n",
    "            \n",
    "            z = pca.inverse_transform(slider_values)\n",
    "            z_transformed = tf.expand_dims(z, axis=0)\n",
    "\n",
    "            # Decode from latent space\n",
    "            model = selectors[dataset][run][model_name]['model']\n",
    "            reco_z = model.decode(z_transformed)\n",
    "            reco_z = plt.cm.Greys(reco_z.numpy().squeeze(), bytes=True)\n",
    "\n",
    "            image_b64 = numpy_to_b64(reco_z, upscale=True, scalar=False)\n",
    "            img_el = html.Img(\n",
    "                src=\"data:image/png;base64, \" + image_b64,\n",
    "                style={\"height\": \"25vh\", \"display\": \"block\", \"margin\": \"auto\"},\n",
    "            )\n",
    "            \n",
    "            comp_df = pd.DataFrame(components, columns=[f\"pc{d+1}\" for d in range(0, n_components)])\n",
    "            comp_agg_df = pd.concat([selectors[dataset][run][model_name]['labels'], comp_df], axis=1).groupby(\"classname\").agg([\"mean\", \"std\"])\n",
    "\n",
    "            raw = \"Class: \" + trace_name + \"\\n\\n\"\n",
    "            raw += \"Original components: \\n\" + str(point) + \"\\n\\n\"\n",
    "            raw += \"Latent vector z: \\n\" + str(z) + \"\\n\\n\"\n",
    "            raw += \"Inner Class Distribution:\\n\" + str(comp_agg_df.loc[trace_name,:]) + \"\\n\\n\"\n",
    "            \n",
    "            return figure, img_el, generate_dim_sliders(n_components, values=point, classname=trace_name, dist=comp_agg_df, latent_dims=MAX_DIMS), None, raw, clickData\n",
    "\n",
    "    else:\n",
    "        print(\"# No point selected, show empty boxes and no sliders\")\n",
    "        figure = px.scatter_matrix(\n",
    "            components_labeled_df, \n",
    "            dimensions=labels, \n",
    "            color=\"classname\", \n",
    "            title=title\n",
    "        )\n",
    "        figure.update_layout(\n",
    "            width=900,\n",
    "            height=900,\n",
    "            clickmode='event+select'\n",
    "        )\n",
    "        figure.update_traces(diagonal_visible=False)\n",
    "        return figure, None, generate_dim_sliders(0, latent_dims=MAX_DIMS), html.H4(\"Select a sample in the SPM to modify latent components\"), None, clickData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748dbe5e-221a-471b-8a12-5ca08506c1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8080/\n",
      "\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n",
      "# No point selected, show empty boxes and no sliders\n"
     ]
    }
   ],
   "source": [
    "app.run_server(debug=True, use_reloader=False, port=\"8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a20f5-bd19-459e-a107-23f1c712b3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
